{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JARINGAN SARAF TIRUAN (NEURAL NETWORK) DENGAN PYTHON (KERAS)\n",
    "=================================================================\n",
    "\n",
    "Adi Sapto Raharjo | Magister Teknik Informatika | 1821211002\n",
    "=================================================================\n",
    "\n",
    "Keras adalah perpustakaan Python open source gratis yang kuat dan mudah digunakan untuk mengembangkan dan mengevaluasi model pembelajaran yang mendalam.\n",
    "\n",
    "Ini membungkus perpustakaan perhitungan numerik yang efisien Theano dan TensorFlow dan memungkinkan Anda untuk mendefinisikan dan melatih model jaringan saraf hanya dalam beberapa baris kode.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memuat Data\n",
    "=================================================================\n",
    "\n",
    "Langkah pertama adalah mendefinisikan fungsi dan kelas yang ingin kita gunakan dalam tutorial ini.\n",
    "Kami akan menggunakan perpustakaan NumPy untuk memuat dataset kami dan kami akan menggunakan dua kelas dari perpustakaan Keras untuk mendefinisikan model kami.\n",
    "Impor yang diperlukan tercantum di bawah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam tutorial Keras ini, kita akan menggunakan dataset diabetes Pima Indian. Ini adalah dataset pembelajaran mesin standar dari repositori Pembelajaran Mesin UCI. Ini menggambarkan data rekam medis pasien untuk orang India Pima dan apakah mereka memiliki diabetes dalam lima tahun.\n",
    "\n",
    "Pastikan dataset tersebut disimpan dalam komputer dan dimasukkan path atau direktori tempat dimana dataset itu disimpan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = loadtxt('D:\\pima-indians-diabetes.csv', delimiter=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita sekarang dapat memuat file sebagai matriks angka menggunakan fungsi NumPy loadtxt ().\n",
    "\n",
    "Ada delapan variabel input dan satu variabel output (kolom terakhir). Kita akan mempelajari sebuah model untuk memetakan baris variabel input (X) ke variabel output (y), yang sering kita ringkas sebagai y = f (X).\n",
    "\n",
    "Variabel dapat diringkas sebagai berikut:\n",
    "*Variabel Input (X):\n",
    "\n",
    "* Number of times pregnant\n",
    "* Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "* Diastolic blood pressure (mm Hg)\n",
    "* Triceps skin fold thickness (mm)\n",
    "* 2-Hour serum insulin (mu U/ml)\n",
    "* Body mass index (weight in kg/(height in m)^2)\n",
    "* Diabetes pedigree function\n",
    "* Age (years)\n",
    "\n",
    "Variabel Keluaran (y):\n",
    "*Variabel kelas (0 atau 1)\n",
    "\n",
    "Setelah file CSV dimuat ke dalam memori, kita dapat membagi kolom data menjadi variabel input dan output.\n",
    "Data akan disimpan dalam array 2D di mana dimensi pertama adalah baris dan dimensi kedua adalah kolom, mis.\n",
    "[baris,kolom].\n",
    "\n",
    "Kita dapat membagi array menjadi dua array dengan memilih subset kolom menggunakan operator slice NumPy standar atau \":\" Kita dapat memilih 8 kolom pertama dari indeks 0 hingga indeks 7 melalui slice 0: 8. Kami kemudian dapat memilih kolom output (variabel ke-9) melalui indeks 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = dataset[:,0:8]\n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mendefinisikan Model Keras\n",
    "=================================================================\n",
    "\n",
    "Model dalam Keras didefinisikan sebagai urutan lapisan.\n",
    "Model Sequential dibuat dan menambahkan layer satu per satu sampai kami puas akan hasil dari arsitektur jaringan ini.\n",
    "\n",
    "Hal pertama yang harus dilakukan adalah memastikan layer input memiliki jumlah fitur input yang tepat. Ini dapat ditentukan saat membuat layer pertama dengan argumen input_dim dan mengaturnya ke 8 untuk 8 variabel input.\n",
    "\n",
    "Kami akan menggunakan fungsi aktivasi unit linear yang diperbaiki yang disebut sebagai ReLU pada dua lapisan pertama dan fungsi Sigmoid di lapisan output.\n",
    "\n",
    "Dulu kasus bahwa fungsi aktivasi Sigmoid dan Tanh lebih disukai untuk semua lapisan. Saat ini, kinerja yang lebih baik dicapai menggunakan fungsi aktivasi ReLU. Kami menggunakan sigmoid pada layer output untuk memastikan output jaringan kami antara 0 dan 1 dan mudah dipetakan ke probabilitas kelas 1 atau snap ke klasifikasi keras dari kedua kelas dengan ambang batas standar 0,5.\n",
    "\n",
    "Kita bisa menyatukan semuanya dengan menambahkan setiap layer:\n",
    "\n",
    "-Model mengharapkan deretan data dengan 8 variabel (argumen input_dim = 8)\n",
    "-Lapisan tersembunyi pertama memiliki 12 node dan menggunakan fungsi aktivasi relu.\n",
    "-Lapisan tersembunyi kedua memiliki 8 node dan menggunakan fungsi aktivasi relu.\n",
    "-Lapisan output memiliki satu node dan menggunakan fungsi aktivasi sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompilasi Keras Model\n",
    "=================================================================\n",
    "\n",
    "Setelah model sudah didefinisikan, kita bisa mengkompilasinya.\n",
    "\n",
    "Mengkompilasi model menggunakan perpustakaan numerik yang efisien di bawah penutup (yang disebut backend) seperti Theano atau TensorFlow. Backend secara otomatis memilih cara terbaik untuk mewakili jaringan untuk pelatihan dan membuat prediksi untuk berjalan pada perangkat keras Anda, seperti CPU atau GPU atau bahkan didistribusikan.\n",
    "\n",
    "Saat mengkompilasi, kita harus menentukan beberapa properti tambahan yang diperlukan saat melatih jaringan. Ingat pelatihan jaringan berarti menemukan set bobot terbaik untuk memetakan input ke output dalam dataset kami.\n",
    "\n",
    "Kita harus menentukan fungsi kehilangan yang digunakan untuk mengevaluasi satu set bobot, optimizer digunakan untuk mencari melalui berbagai bobot untuk jaringan dan metrik opsional apa pun yang ingin kami kumpulkan dan laporkan selama pelatihan.\n",
    "\n",
    "Dalam hal ini, kita akan menggunakan cross entropy sebagai argumen loss. Kerugian ini untuk masalah klasifikasi biner dan didefinisikan dalam Keras sebagai \"binary_crossentropy\".\n",
    "\n",
    "Kami akan mendefinisikan pengoptimal sebagai algoritme gradien keturunan stokastik efisien \"adam\". Ini adalah versi populer dari gradient descent karena secara otomatis menyetel dirinya sendiri dan memberikan hasil yang baik dalam berbagai masalah.\n",
    "\n",
    "karena ini adalah masalah klasifikasi, kami akan mengumpulkan dan melaporkan keakuratan klasifikasi, yang didefinisikan melalui argumen metrik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit Keras Model\n",
    "=================================================================\n",
    "\n",
    "Kami telah mendefinisikan model kami dan mengkompilasinya siap untuk perhitungan yang efisien.\n",
    "Sekarang saatnya untuk mengeksekusi model pada beberapa data.\n",
    "\n",
    "Kita dapat melatih atau menyesuaikan model kita pada data yang dimuat dengan memanggil fungsi fit () pada model.\n",
    "\n",
    "Pelatihan terjadi pada zaman dan setiap zaman dibagi menjadi beberapa kelompok.\n",
    "\n",
    "* Epoch: Satu melewati semua baris dalam dataset pelatihan.\n",
    "* Batch: Satu atau lebih sampel dipertimbangkan oleh model dalam epoch sebelum bobot diperbarui.\n",
    "\n",
    "Proses pelatihan akan berjalan untuk sejumlah iterasi tetap melalui dataset yang disebut epochs, yang harus kita tentukan menggunakan argumen epochs. Kita juga harus mengatur jumlah baris dataset yang dipertimbangkan sebelum bobot model diperbarui dalam setiap zaman, yang disebut ukuran batch dan ditetapkan menggunakan argumen batch_size.\n",
    "\n",
    "Untuk masalah ini, kita akan berlari untuk sejumlah kecil zaman (150) dan menggunakan ukuran batch yang relatif kecil yaitu 10. Ini berarti bahwa setiap zaman akan melibatkan (150/10) 15 pembaruan pada bobot model.\n",
    "\n",
    "Konfigurasi ini dapat dipilih secara eksperimental dengan coba-coba. Kami ingin melatih model cukup sehingga ia belajar pemetaan baris input data yang baik (atau cukup baik) ke klasifikasi output. Model akan selalu memiliki beberapa kesalahan, tetapi jumlah kesalahan akan keluar setelah beberapa titik untuk konfigurasi model yang diberikan. Ini disebut model konvergensi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\DOWNLOAD\\Programs\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "768/768 [==============================] - 2s 3ms/step - loss: 5.3025 - acc: 0.5938\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 3.7186 - acc: 0.6393\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 3.1116 - acc: 0.6185\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 1.2224 - acc: 0.5911\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 1.0364 - acc: 0.6289\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.9374 - acc: 0.6263\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.8878 - acc: 0.6237\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.7942 - acc: 0.6432\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.7665 - acc: 0.6263\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7429 - acc: 0.6393\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.7069 - acc: 0.6497\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6857 - acc: 0.6615\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6792 - acc: 0.6484\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.6504 - acc: 0.6484\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.6513 - acc: 0.6536\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.6395 - acc: 0.6797\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.6322 - acc: 0.6797\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.6174 - acc: 0.6888\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.6260 - acc: 0.6784\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.6003 - acc: 0.6888\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.6005 - acc: 0.6940\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.6091 - acc: 0.6771\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5813 - acc: 0.7031\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.5904 - acc: 0.7070\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 366us/step - loss: 0.5771 - acc: 0.7122\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 264us/step - loss: 0.5979 - acc: 0.6823\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5733 - acc: 0.7122\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5818 - acc: 0.6979\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5841 - acc: 0.6901\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 244us/step - loss: 0.5872 - acc: 0.6888\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5628 - acc: 0.7018\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5665 - acc: 0.7240\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5569 - acc: 0.7292\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5764 - acc: 0.6979\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5651 - acc: 0.7174\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5583 - acc: 0.7148\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5732 - acc: 0.6966\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5512 - acc: 0.7083\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5593 - acc: 0.7135\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5724 - acc: 0.7005\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5564 - acc: 0.7201\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5580 - acc: 0.7292\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5709 - acc: 0.7135\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5604 - acc: 0.7201\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5558 - acc: 0.7201\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5488 - acc: 0.7161\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5489 - acc: 0.7214\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5477 - acc: 0.7135\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5542 - acc: 0.7266\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5523 - acc: 0.7188\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 224us/step - loss: 0.5579 - acc: 0.7018\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5840 - acc: 0.6901\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5546 - acc: 0.7109\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5574 - acc: 0.7044\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5569 - acc: 0.7109\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5443 - acc: 0.7122\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5418 - acc: 0.7344\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5449 - acc: 0.7266\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5431 - acc: 0.7188\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5347 - acc: 0.7409\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5503 - acc: 0.7240\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5509 - acc: 0.7266\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5497 - acc: 0.7292\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5289 - acc: 0.7396\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5664 - acc: 0.7174\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5812 - acc: 0.7057\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5318 - acc: 0.7331\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5223 - acc: 0.7552\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5427 - acc: 0.7174\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5369 - acc: 0.7148\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5289 - acc: 0.7253\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5428 - acc: 0.7070\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5297 - acc: 0.7383\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5225 - acc: 0.7292\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5296 - acc: 0.7357\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5331 - acc: 0.7383\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5345 - acc: 0.7305\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5186 - acc: 0.7370\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5253 - acc: 0.7448\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5443 - acc: 0.7148\n",
      "Epoch 81/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 142us/step - loss: 0.5203 - acc: 0.7461\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5200 - acc: 0.7318\n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5271 - acc: 0.7370\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5189 - acc: 0.7461\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5190 - acc: 0.7279\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5362 - acc: 0.7305\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5397 - acc: 0.7292\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5262 - acc: 0.7357\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5262 - acc: 0.7435\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5247 - acc: 0.7396\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.5186 - acc: 0.7331\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5223 - acc: 0.7357\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5143 - acc: 0.7409\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5265 - acc: 0.7448\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.5373 - acc: 0.7409\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5158 - acc: 0.7448\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5152 - acc: 0.7474\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5241 - acc: 0.7396\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5152 - acc: 0.7539\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5184 - acc: 0.7383\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5127 - acc: 0.7474\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5152 - acc: 0.7344\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5087 - acc: 0.7409\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5131 - acc: 0.7565\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5143 - acc: 0.7331\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5096 - acc: 0.7500\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5017 - acc: 0.7526\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5087 - acc: 0.7513\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5044 - acc: 0.7526\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5209 - acc: 0.7383\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4915 - acc: 0.7526\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5239 - acc: 0.7435\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5192 - acc: 0.7409\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4975 - acc: 0.7526\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5044 - acc: 0.7487\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5137 - acc: 0.7409\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4952 - acc: 0.7591\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4952 - acc: 0.7513\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5114 - acc: 0.7513\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4949 - acc: 0.7435\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4930 - acc: 0.7487\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5060 - acc: 0.7422\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4951 - acc: 0.7669\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4973 - acc: 0.7383\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5075 - acc: 0.7578\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5147 - acc: 0.7318\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4988 - acc: 0.7578\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4864 - acc: 0.7565\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 203us/step - loss: 0.4911 - acc: 0.7656\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4987 - acc: 0.7656\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4945 - acc: 0.7565\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4959 - acc: 0.7539\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4955 - acc: 0.7500\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4954 - acc: 0.7565\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 163us/step - loss: 0.4848 - acc: 0.7630\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4870 - acc: 0.7708\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.5180 - acc: 0.7539\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5073 - acc: 0.7526\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5114 - acc: 0.7656\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4901 - acc: 0.7591\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5028 - acc: 0.7643\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.5159 - acc: 0.7526\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4928 - acc: 0.7474\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4934 - acc: 0.7539\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4976 - acc: 0.7656\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4979 - acc: 0.7617\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 122us/step - loss: 0.4845 - acc: 0.7682\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 142us/step - loss: 0.4995 - acc: 0.7578\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.5019 - acc: 0.7539\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 183us/step - loss: 0.4874 - acc: 0.7591\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295acfe0be0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi Model Keras\n",
    "=================================================================\n",
    "\n",
    "Kami telah melatih jaringan saraf kami pada seluruh dataset dan kami dapat mengevaluasi kinerja jaringan pada dataset yang sama.\n",
    "\n",
    "Ini hanya akan memberi kita gambaran tentang seberapa baik kita telah memodelkan dataset (mis. Akurasi kereta), tetapi tidak tahu seberapa baik algoritma dapat bekerja pada data baru. Kami telah melakukan ini untuk kesederhanaan, tetapi idealnya, Anda dapat memisahkan data Anda ke dalam set data kereta dan uji untuk pelatihan dan evaluasi model Anda.\n",
    "\n",
    "Anda dapat mengevaluasi model Anda pada dataset pelatihan Anda menggunakan fungsi evalu () pada model Anda dan memberikan input dan output yang sama dengan yang digunakan untuk melatih model.\n",
    "\n",
    "Ini akan menghasilkan prediksi untuk setiap pasangan input dan output dan mengumpulkan skor, termasuk kehilangan rata-rata dan metrik apa pun yang telah Anda konfigurasi, seperti akurasi.\n",
    "\n",
    "Fungsi evaluate () akan mengembalikan daftar dengan dua nilai. Yang pertama adalah hilangnya model pada dataset dan yang kedua adalah akurasi model pada dataset. Kami hanya tertarik untuk melaporkan keakuratan, sehingga kami akan mengabaikan nilai kerugiannya.\n",
    "\n",
    "Berikut adalah hasil akurasi yang diambil dari fungsi evaluate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 203us/step\n",
      "Accuracy: 77.99\n"
     ]
    }
   ],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Akurasi tersebut akan berubah apabila dataset diatas diulangi proses *fit*-nya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selesai\n",
    "=================================================================\n",
    "\n",
    "Terima kasih, mohon maaf atas kekurangan atau kesalahan kata.\n",
    "\n",
    "Disusun dan Ditulis oleh *Adi Sapto Raharjo*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
